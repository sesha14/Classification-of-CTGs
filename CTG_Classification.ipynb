{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "0.9845377798380271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       324\n",
      "           1       0.95      0.95      0.95        66\n",
      "           2       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       425\n",
      "   macro avg       0.98      0.98      0.98       425\n",
      "weighted avg       0.99      0.99      0.99       425\n",
      " samples avg       0.99      0.99      0.99       425\n",
      "\n",
      "MLP\n",
      "0.9761869447545188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       324\n",
      "           1       0.95      0.92      0.94        66\n",
      "           2       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       425\n",
      "   macro avg       0.98      0.97      0.98       425\n",
      "weighted avg       0.98      0.98      0.98       425\n",
      " samples avg       0.98      0.98      0.98       425\n",
      "\n",
      "Perceptron\n",
      "0.9687962191305423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       324\n",
      "           1       0.94      0.92      0.93        66\n",
      "           2       1.00      0.97      0.99        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       425\n",
      "   macro avg       0.97      0.96      0.97       425\n",
      "weighted avg       0.98      0.98      0.98       425\n",
      " samples avg       0.98      0.98      0.98       425\n",
      "\n",
      "Decisiontree\n",
      "0.9714657403422798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       324\n",
      "           1       0.87      0.94      0.91        66\n",
      "           2       0.97      0.97      0.97        35\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       425\n",
      "   macro avg       0.95      0.96      0.95       425\n",
      "weighted avg       0.97      0.97      0.97       425\n",
      " samples avg       0.97      0.97      0.97       425\n",
      "\n",
      "Random forest\n",
      "0.981341018141843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       324\n",
      "           1       0.97      0.94      0.95        66\n",
      "           2       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       425\n",
      "   macro avg       0.99      0.98      0.98       425\n",
      "weighted avg       0.99      0.99      0.99       425\n",
      " samples avg       0.99      0.99      0.99       425\n",
      "\n",
      "Gradientboost\n",
      "0.9694955344306004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       324\n",
      "           1       0.98      0.94      0.96        66\n",
      "           2       1.00      0.94      0.97        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       425\n",
      "   macro avg       0.99      0.96      0.97       425\n",
      "weighted avg       0.98      0.98      0.98       425\n",
      " samples avg       0.98      0.98      0.98       425\n",
      "\n",
      "Adaboost\n",
      "0.9563344872976045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       324\n",
      "           1       0.75      0.94      0.83        66\n",
      "           2       1.00      0.97      0.99        35\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       425\n",
      "   macro avg       0.91      0.95      0.93       425\n",
      "weighted avg       0.95      0.94      0.94       425\n",
      " samples avg       0.94      0.94      0.94       425\n",
      "\n",
      "KNN\n",
      "0.9752082889089486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       324\n",
      "           1       0.94      0.92      0.93        66\n",
      "           2       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       425\n",
      "   macro avg       0.97      0.97      0.97       425\n",
      "weighted avg       0.98      0.98      0.98       425\n",
      " samples avg       0.98      0.98      0.98       425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#load data\n",
    "df1 = pd.read_excel('CTG.xls', \"Raw Data\")\n",
    "\n",
    "#drop missing values\n",
    "df=df1.dropna()\n",
    "\n",
    "#x,y data\n",
    "X = df.iloc[1:2126, 3:-2].values\n",
    "y = df.iloc[1:2126, -1].values\n",
    "\n",
    "#split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "#pca.fit(X_train)\n",
    "\n",
    "#SVM classifier\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred=svc.predict(X_test)\n",
    "\n",
    "#label binarizer\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "y_pred = lb.transform(y_pred)\n",
    "average=\"macro\"\n",
    "\n",
    "#metrics valuation    \n",
    "print(\"SVC\")\n",
    "print(roc_auc_score(y_test, y_pred, average=average))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#MLP classifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred=mlp.predict(X_test)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "y_pred = lb.transform(y_pred)\n",
    "average=\"macro\"\n",
    "\n",
    "#metrics valuation\n",
    "print(\"MLP\")\n",
    "print(roc_auc_score(y_test, y_pred, average=average))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#Perceptron classifier\n",
    "p = Perceptron()\n",
    "p.fit(X_train, y_train)\n",
    "y_pred=p.predict(X_test)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "y_pred = lb.transform(y_pred)\n",
    "average=\"macro\"\n",
    "\n",
    "#metrics valuation\n",
    "print(\"Perceptron\")\n",
    "print(roc_auc_score(y_test, y_pred, average=average))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#Decision tree classifier\n",
    "d = DecisionTreeClassifier()\n",
    "d.fit(X_train, y_train)\n",
    "y_pred=d.predict(X_test)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "y_pred = lb.transform(y_pred)\n",
    "average=\"macro\"\n",
    "\n",
    "#metrics valuation    \n",
    "print(\"Decisiontree\")\n",
    "print(roc_auc_score(y_test, y_pred, average=average))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#Random forest classifier\n",
    "r = RandomForestClassifier()\n",
    "r.fit(X_train, y_train)\n",
    "y_pred=r.predict(X_test)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "y_pred = lb.transform(y_pred)\n",
    "average=\"macro\"\n",
    "\n",
    "#metrics valuation\n",
    "print(\"Random forest\")\n",
    "print(roc_auc_score(y_test, y_pred, average=average))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#Gradient boosting\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred=gb.predict(X_test)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "y_pred = lb.transform(y_pred)\n",
    "average=\"macro\"\n",
    "\n",
    "#metrics valuation\n",
    "print(\"Gradientboost\")\n",
    "print(roc_auc_score(y_test, y_pred, average=average))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#Adaboost classifier\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(X_train, y_train)\n",
    "y_pred=ab.predict(X_test)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "y_pred = lb.transform(y_pred)\n",
    "average=\"macro\"\n",
    "\n",
    "#metrics valuation\n",
    "print(\"Adaboost\")\n",
    "print(roc_auc_score(y_test, y_pred, average=average))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_test)\n",
    "y_test = lb.transform(y_test)\n",
    "y_pred = lb.transform(y_pred)\n",
    "average=\"macro\"\n",
    "\n",
    "#metrics valuation\n",
    "print(\"KNN\")\n",
    "print(roc_auc_score(y_test, y_pred, average=average))\n",
    "print(classification_report(y_test,y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SESHA SAI SREEVANI KAPPAGANTULA\n",
    "#N11264916\n",
    "#SSK785\n",
    "#CLASSIFICATION ON CARDIOTOCOGRAPHY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
